{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "single-point-regression-gradient.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manansethia/IOAI/blob/main/single-point-regression-gradient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlQvcmWWNd4Y"
      },
      "source": [
        "# Gradient of a Single-Point Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JtUZ9KYNd4Z"
      },
      "source": [
        "In this notebook, we calculate the gradient of quadratic cost with respect to a straight-line regression model's parameters. We keep the partial derivatives as simple as possible by limiting the model to handling a single data point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdScrjQCNd4Z"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnFhWE9kNd4d"
      },
      "source": [
        "Let's use the same data as we did in the [*Regression in PyTorch* notebook](https://github.com/jonkrohn/ML-foundations/blob/master/notebooks/regression-in-pytorch.ipynb) as well as for demonstrating the Moore-Penrose Pseudoinverse in the [*Linear Algebra II* notebook](https://github.com/jonkrohn/ML-foundations/blob/master/notebooks/2-linear-algebra-ii.ipynb):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oem10L3iNd4d"
      },
      "source": [
        "xs = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7.])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPZsXuwWNd4f"
      },
      "source": [
        "ys = torch.tensor([1.86, 1.31, .62, .33, .09, -.67, -1.23, -1.37])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM6hk9NeNd4i"
      },
      "source": [
        "The slope of a line is given by $y = mx + b$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtyilFoYNd4i"
      },
      "source": [
        "def regression(my_x, my_m, my_b):\n",
        "    return my_m*my_x + my_b"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROV3p3BHNd4l"
      },
      "source": [
        "Let's initialize $m$ and $b$ with the same \"random\" near-zero values as we did in the *Regression in PyTorch* notebook:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmiBbvH1Nd4l"
      },
      "source": [
        "m = torch.tensor([0.9]).requires_grad_()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRxe0rU9Nd4n"
      },
      "source": [
        "b = torch.tensor([0.1]).requires_grad_()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Iu4uKsqNd4r"
      },
      "source": [
        "To keep the partial derivatives as simple as possible, let's move forward with a single instance $i$ from the eight possible data points:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ttss5lTNd4s"
      },
      "source": [
        "i = 7\n",
        "x = xs[i]\n",
        "y = ys[i]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO7ozmjeNd4u",
        "outputId": "1d24fb03-83b5-4670-c7ab-bd83525e1663"
      },
      "source": [
        "x"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b63IzdS1Nd4x",
        "outputId": "b84a0f63-3421-4f0a-bae5-a5f570002da7"
      },
      "source": [
        "y"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-1.3700)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVkbo0oPNd4z"
      },
      "source": [
        "**Step 1**: Forward pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_bUxX__Nd4z"
      },
      "source": [
        "We can flow the scalar tensor $x$ through our regression model to produce $\\hat{y}$, an estimate of $y$. Prior to any model training, this is an arbitrary estimate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBB2iwPiNd40",
        "outputId": "9745899b-b93f-4558-c5b8-47643065524f"
      },
      "source": [
        "yhat = regression(x, m, b)\n",
        "yhat"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6.4000], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hy2sDlNNd42"
      },
      "source": [
        "**Step 2**: Compare $\\hat{y}$ with true $y$ to calculate cost $C$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtHOeylJNd43"
      },
      "source": [
        "In the *Regression in PyTorch* notebook, we used mean-squared error, which averages quadratic cost over multiple data points. With a single data point, here we can use quadratic cost alone. It is defined by: $$ C = (\\hat{y} - y)^2 $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-THZMH0Nd43"
      },
      "source": [
        "def squared_error(my_yhat, my_y):\n",
        "    return (my_yhat - my_y)**2"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LSKXx5XNd45",
        "outputId": "ea8cb1b4-0024-418c-cd46-baca10d0f989"
      },
      "source": [
        "C = squared_error(yhat, y)\n",
        "C"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([60.3729], grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu4nlO3-Nd47"
      },
      "source": [
        "**Step 3**: Use autodiff to calculate gradient of $C$ w.r.t. parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk9Lx-gTNd48"
      },
      "source": [
        "C.backward()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXQJxYduNd4-"
      },
      "source": [
        "The partial derivative of $C$ with respect to $m$ ($\\frac{\\partial C}{\\partial m}$) is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yQ7w1bfNd4-",
        "outputId": "dc25a0f7-5e6d-43e1-b042-e6dad5603f34"
      },
      "source": [
        "m.grad"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([108.7800])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGK1NwomNd5B"
      },
      "source": [
        "And the partial derivative of $C$ with respect to $b$ ($\\frac{\\partial C}{\\partial b}$) is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIeBu-tINd5B",
        "outputId": "b2ad5613-03bc-4a72-e6eb-c5c48faa4853"
      },
      "source": [
        "b.grad"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([15.5400])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK1tyH4WNd5E"
      },
      "source": [
        "**Return to *Calculus II* slides here to derive $\\frac{\\partial C}{\\partial m}$ and $\\frac{\\partial C}{\\partial b}$.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTgfR-wINd5F"
      },
      "source": [
        "$$ \\frac{\\partial C}{\\partial m} = 2x(\\hat{y} - y) $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKjWDa4QNd5F",
        "outputId": "9925311e-4ff8-4dff-d199-5ee8b611423a"
      },
      "source": [
        "2*x*(yhat.item()-y)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(108.7800)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCV3zMIjNd5H"
      },
      "source": [
        "$$ \\frac{\\partial C}{\\partial b} = 2(\\hat{y}-y) $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNrOSpcONd5H",
        "outputId": "e574623e-d2bf-4015-c838-5b71121b0f84"
      },
      "source": [
        "2*(yhat.item()-y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(15.5400)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXor7Ev7Nd5J"
      },
      "source": [
        "### The Gradient of Cost, $\\nabla C$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeII8EHQNd5K"
      },
      "source": [
        "The gradient of cost, which is symbolized $\\nabla C$ (pronounced \"nabla C\"), is a vector of all the partial derivatives of $C$ with respect to each of the individual model parameters:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVnD7j3HNd5K"
      },
      "source": [
        "$\\nabla C = \\nabla_p C = \\left[ \\frac{\\partial{C}}{\\partial{p_1}}, \\frac{\\partial{C}}{\\partial{p_2}}, \\cdots, \\frac{\\partial{C}}{\\partial{p_n}} \\right]^T $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILK7BRLJNd5K"
      },
      "source": [
        "In this case, there are only two parameters, $b$ and $m$:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Yq3BQ3YNd5L"
      },
      "source": [
        "$\\nabla C = \\left[ \\frac{\\partial{C}}{\\partial{b}}, \\frac{\\partial{C}}{\\partial{m}} \\right]^T $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsZhOKFZNd5L",
        "outputId": "f250f0d6-d0b4-4fdb-e708-736bc200f397"
      },
      "source": [
        "gradient = torch.tensor([[b.grad.item(), m.grad.item()]]).T\n",
        "gradient"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 15.5400],\n",
              "        [108.7800]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}